cuda: true
gpu: 0
exp_name: mike_central_layer2_surround
pc_paths: ./test_file/mike/pointcloud_central.npy # 場景點雲路徑
vis_output: ./vis_grasp/ # 儲存視覺化地方
vis_lot_grasp: true  # 是否畫很多個grasp
vis_grasp_nums: 99   # 畫幾個grasp
vis_surround: true # 視覺化時是否環繞拍攝

# 須配合機械手臂和環境調整的參數
eval_width: 0.06 # 機器手臂夾爪寬度
all_points_num: 25600 # 點雲sample的point數量
table_height: 0 # 會把高度低於該值得grasp pose篩掉
bounds: [-1, 1, -1, 1] # 會把超出該範圍的grasp 篩掉
z_rescale: 1.2 # 把z軸的差距拉大
camera_transform:
  euler_deg: [-160, 0.0, 180.0]  # XYZ 歐拉角
  translation: [0.0, 0.0, 0.5]     # T_x, T_y, T_z
  # mike 超參
  # euler_deg: [-160, 0.0, 180.0]  # XYZ 歐拉角
  # translation: [0.0, 0.0, 0.5]     # T_x, T_y, T_z
  # our2 超參
  # euler_deg: [-147.6, 0.0, 180.0] 
  # translation: [0.0, 0.0, 0.6]     
  # our3 的超參
  # euler_deg: [-60, 0.0, 180.0] 
  # translation: [0.0, 0.0, 0.25]     
# 夾爪超參數在/home/tomyeh/env/REGNet-v2/REGNet-V2/dataset_utils/eval_score/configs/config.py
# 當中包含夾爪爪寬、深度...資訊，用來檢查碰撞

# 方法內部參數，我們不用去調整
# layer2在我們data上比layer1發揮的好非常多，很多時候layer1找不到半個grasp，layer2能產生近百個
method: multigrasp_layer2 # 分為multigrasp_layer1和multigrasp_layer2，1預測出的grasp變異性較低但成功率平均更高，2能得到更多樣化預測，但平均成功率較低
load_model: test_assets/multigrasp_layer2/refine_15.model # 須配合method更改layer
use_region: true # 本篇方法提出的"將關鍵點附近的全部點一起丟入算特徵"功能
use_analytic: false # 訓練時計算loss用的，inference用不到
camera: our # 就只是個名稱，拿來分辨不同機型相機時使用的調整

# python grasp_detect_from_file_multiobjects.py --config config.yaml